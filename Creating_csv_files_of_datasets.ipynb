{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM90BaqH1kp9RCQ15m5iX6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Boris2232/Machine-Learning-Project/blob/main/Creating_csv_files_of_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O66f91hZZSe6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import shutil\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Utk datatset have three parts format\"part{k}.tar.gz\"\n",
        "# this code extracts all images and its labels from the .gz archive and collects all data into one csv file with labels:[\"file\",\"age\", \"age_range\",\"gender\",\"race\",\"split\",\"emotion\"]\n",
        "# https://susanqq.github.io/UTKFace/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I have downloaded UTK dataset from the site. UTK does not have 'split'\n",
        "# UTK faces data collecting:\n",
        "open(\"UTK_faces.csv\", \"w\").close()\n",
        "for k in range(1, 4):\n",
        "    with tarfile.open(f'part{k}.tar.gz', 'r:gz') as folder:\n",
        "        members = folder.getnames()\n",
        "        names = list(map(lambda x: x.split(f'part{k}/')[-1], members))\n",
        "        csv_headers = [\"file\", \"age\", \"age_range\", \"gender\", \"race\", \"split\", \"emotion\"]\n",
        "        with open('UTK_faces.csv', mode='a', encoding='utf-8') as file:\n",
        "            file_writer = csv.DictWriter(file, delimiter=';', fieldnames=csv_headers, lineterminator='\\r')\n",
        "            if k == 1:\n",
        "                file_writer.writeheader()\n",
        "            for i in names:\n",
        "                obj = i.split('_')[:-1:]\n",
        "                if len(obj) > 2:\n",
        "                    age = obj[0]\n",
        "                    gender = obj[1]\n",
        "                    race = obj[2]\n",
        "                    file_writer.writerow(\n",
        "                        {\"file\": i, \"age\": age, \"age_range\": np.NaN, \"gender\": gender, \"race\": race, \"split\": np.NaN,\n",
        "                         \"emotion\": np.NaN})\n",
        "# now we had collected all data from all parts of datasets, and we wrote all data in a separate file named UTK_Faces.\n",
        "# After collecting all data from other datasets we can make a general table.\n",
        "# final step - collect data from a fair-face dataset\n",
        "csv_headers = [\"file\", \"age\", \"age_range\", \"gender\", \"race\", \"split\", \"emotion\"]\n",
        "with open('Fair-Face.csv', mode='wt', encoding='utf-8') as table:\n",
        "    file_writer = csv.DictWriter(table, delimiter=';', fieldnames=csv_headers, lineterminator='\\r')\n",
        "    file_writer.writeheader()\n",
        "    with open('fairface_label_train.csv') as csvfile:\n",
        "        reader = csv.DictReader(csvfile, delimiter=',')\n",
        "        for i in reader:\n",
        "            file_writer.writerow(\n",
        "                {\"file\": i['file'], \"age\": np.NaN,\n",
        "                 \"age_range\": i['age'],\n",
        "                 \"gender\": i['gender'], \"race\": i['race'], \"split\": i['file'].split('/')[0],\n",
        "                 \"emotion\": np.NaN})\n",
        "    with open('fairface_label_val.csv') as csv_f:\n",
        "        reader = csv.DictReader(csv_f, delimiter=',')\n",
        "        for i in reader:\n",
        "            file_writer.writerow(\n",
        "                {\"file\": i['file'], \"age\": np.NaN,\n",
        "                 \"age_range\": i['age'],\n",
        "                 \"gender\": i['gender'], \"race\": i['race'], \"split\": i['file'].split('/')[0],\n",
        "                 \"emotion\": np.NaN})"
      ],
      "metadata": {
        "id": "JcBt-jQ8ZZ3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAF-DB is a dataset which contains labels of emotions and it is splitted to train/test parts\n",
        "# http://www.whdeng.cn/raf/model1.html#dataset\n",
        "\n",
        "\n",
        "# It's time to collect data from RAF-DB\n",
        "zip_name = 'Annotations-20230618T142719Z-001.zip'\n",
        "#  First of all lets unpack the zip file\n",
        "with zipfile.ZipFile(zip_name, 'r') as file:\n",
        "    annotations = file.extract('Annotations/manual.zip')\n",
        "    file.extract('Annotations/list_patition_label.txt')\n",
        "#  let's extract manual\n",
        "with zipfile.ZipFile('Annotations/manual.zip', 'r') as file:\n",
        "    file.extractall('Annotations')\n",
        "# let's parse through the folder and create new csv file\n",
        "csv_headers = [\"file\", \"age\", \"age_range\", \"gender\", \"race\", \"split\", \"emotion\"]\n",
        "emotions = [i.split()[1].rstrip('\\n') for i in open('Annotations/list_patition_label.txt', 'r').readlines()]\n",
        "with open('RAF_DB.csv', mode='wt', encoding='utf-8') as table:\n",
        "    file_writer = csv.DictWriter(table, delimiter=';', fieldnames=csv_headers, lineterminator='\\r')\n",
        "    file_writer.writeheader()\n",
        "    counter = 0\n",
        "    for i in os.listdir('Annotations/manual'):\n",
        "        with open(f'Annotations/manual/{i}', 'r') as file:\n",
        "            new_data = list(file.readlines())\n",
        "            gender, race, age_range = [data.strip('\\n') for data in new_data[5::]]\n",
        "            emotion = emotions[counter]\n",
        "            file_writer.writerow(\n",
        "                {\"file\": i, \"age\": {0: '0-3', 1: '4-19', 2: '20-39', 3: '40-69', 4: '70+'}[int(age_range)],\n",
        "                 \"age_range\": age_range,\n",
        "                 \"gender\": gender, \"race\": race, \"split\": i.split('_')[0],\n",
        "                 \"emotion\": emotion})\n",
        "            counter += 1\n",
        "shutil.rmtree('Annotations')"
      ],
      "metadata": {
        "id": "8qsg0nHrblxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FairFace's authors provided all data in csv table. It is already splitted.(we created two separate tables)\n",
        "# https://github.com/joojs/fairface\n",
        "\n",
        "\n",
        "\n",
        "# final step - collect data from a fair-face dataset\n",
        "csv_headers = [\"file\", \"age\", \"age_range\", \"gender\", \"race\", \"split\", \"emotion\"]\n",
        "with open('Fair-Face.csv', mode='wt', encoding='utf-8') as table:\n",
        "    file_writer = csv.DictWriter(table, delimiter=';', fieldnames=csv_headers, lineterminator='\\r')\n",
        "    file_writer.writeheader()\n",
        "    with open('fairface_label_train.csv') as csvfile:\n",
        "        reader = csv.DictReader(csvfile, delimiter=',')\n",
        "        for i in reader:\n",
        "            file_writer.writerow(\n",
        "                {\"file\": i['file'], \"age\": np.NaN,\n",
        "                 \"age_range\": i['age'],\n",
        "                 \"gender\": i['gender'], \"race\": i['race'], \"split\": i['file'].split('/')[0],\n",
        "                 \"emotion\": np.NaN})\n",
        "    with open('fairface_label_val.csv') as csv_f:\n",
        "        reader = csv.DictReader(csv_f, delimiter=',')\n",
        "        for i in reader:\n",
        "            file_writer.writerow(\n",
        "                {\"file\": i['file'], \"age\": np.NaN,\n",
        "                 \"age_range\": i['age'],\n",
        "                 \"gender\": i['gender'], \"race\": i['race'], \"split\": i['file'].split('/')[0],\n",
        "                 \"emotion\": np.NaN})"
      ],
      "metadata": {
        "id": "3ysKES09btZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UTK\n",
        "# file;age;age_range;gender;race;split;emotion\n",
        "# 2_1_2_20161219202547820.jpg;2;nan;1;2;nan;nan\n",
        "# 77_1_0_20170110122639530.jpg;77;nan;1;0;nan;nan\n",
        "# 1_1_0_20170109190844250.jpg;1;nan;1;0;nan;nan\n",
        "# 29_1_2_20170105164315483.jpg;29;nan;1;2;nan;nan\n",
        "# 76_1_0_20170110131744527.jpg;76;nan;1;0;nan;nan\n",
        "# 50_1_0_20170110154254311.jpg;50;nan;1;0;nan;nan\n",
        "# 2_1_2_20161219152918020.jpg;2;nan;1;2;nan;nan\n",
        "# 5_1_0_20170109194229104.jpg;5;nan;1;0;nan;nan\n",
        "# 81_1_2_20170105174804349.jpg;81;nan;1;2;nan;nan\n",
        "# 30_0_0_20170105164847516.jpg;30;nan;0;0;nan;nan\n",
        "\n",
        "\n",
        "\n",
        "# RAF\n",
        "# file;age;age_range;gender;race;split;emotion\n",
        "# test_0001_manu_attri.txt;20-39;2;1;2;test;5\n",
        "# test_0002_manu_attri.txt;4-19;1;1;2;test;5\n",
        "# test_0003_manu_attri.txt;4-19;1;1;0;test;4\n",
        "# test_0004_manu_attri.txt;20-39;2;1;0;test;4\n",
        "# test_0005_manu_attri.txt;4-19;1;2;2;test;5\n",
        "# test_0006_manu_attri.txt;20-39;2;1;0;test;1\n",
        "# test_0007_manu_attri.txt;20-39;2;0;0;test;5\n",
        "# test_0008_manu_attri.txt;20-39;2;0;0;test;4\n",
        "# test_0009_manu_attri.txt;20-39;2;1;0;test;4\n",
        "# test_0010_manu_attri.txt;40-69;3;1;0;test;1\n",
        "# test_0011_manu_attri.txt;20-39;2;1;0;test;4\n",
        "# test_0012_manu_attri.txt;20-39;2;0;2;test;1\n",
        "# test_0013_manu_attri.txt;40-69;3;0;0;test;1\n",
        "# test_0014_manu_attri.txt;20-39;2;1;2;test;4\n",
        "# test_0015_manu_attri.txt;20-39;2;0;0;test;5\n",
        "# test_0016_manu_attri.txt;4-19;1;1;0;test;4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# FairFace\n",
        "# file;age;age_range;gender;race;split;emotion\n",
        "# train/1.jpg;nan;50-59;Male;East Asian;train;nan\n",
        "# train/2.jpg;nan;30-39;Female;Indian;train;nan\n",
        "# train/3.jpg;nan;3-9;Female;Black;train;nan\n",
        "# train/4.jpg;nan;20-29;Female;Indian;train;nan\n",
        "# train/5.jpg;nan;20-29;Female;Indian;train;nan\n",
        "# train/6.jpg;nan;20-29;Male;White;train;nan\n",
        "# train/7.jpg;nan;40-49;Male;Middle Eastern;train;nan\n",
        "# train/8.jpg;nan;30-39;Female;Indian;train;nan\n",
        "# train/9.jpg;nan;10-19;Male;White;train;nan\n",
        "# train/10.jpg;nan;30-39;Male;Middle Eastern;train;nan\n",
        "# train/11.jpg;nan;50-59;Male;East Asian;train;nan\n",
        "# train/12.jpg;nan;20-29;Male;East Asian;train;nan\n",
        "# train/13.jpg;nan;20-29;Male;Latino_Hispanic;train;nan\n",
        "# train/14.jpg;nan;10-19;Male;Indian;train;nan"
      ],
      "metadata": {
        "id": "GwzlrZIOc1CP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}